{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9ddc75047441>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gpy'"
     ]
    }
   ],
   "source": [
    "# Implementation of Gaussian Process for utility inference using Pairwise Comparison \n",
    "# Details see:\n",
    "#   1. \"A Tutorial on Bayesian Optimization of Expensive Cost Functions\"\n",
    "#   2. \"Preference learning with Gaussian processes\" (ICML 2005)\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "from scipy.stats import norm\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    \"\"\"Dataset class\n",
    "    \n",
    "    Attributes:\n",
    "        datapoints: matrix for datapoints (dimension t x n)\n",
    "        comparisons: matrix for comparisons (dimension m x 2)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_features):\n",
    "        \"\"\"Inits Dataset with the number of features\"\"\"\n",
    "        self.datapoints = np.empty((0, num_features))\n",
    "        self.comparisons = np.empty((0, 2), dtype=np.int)\n",
    "\n",
    "    def add_single_comparison(self, sup, inf):\n",
    "        \"\"\"Adds a single comparison to the dataset.\n",
    "        \n",
    "        Args:\n",
    "            sup: The datapoint index that is superior in the comparison.\n",
    "            inf: The datapoint index that is inferior in the comparison.\n",
    "        \"\"\"\n",
    "        # add superior and inferior to our datapoints and get the indices in dataset\n",
    "        sup_idx = self._add_single_datapoint(sup)\n",
    "        inf_idx = self._add_single_datapoint(inf)\n",
    "        self.comparisons = np.vstack((self.comparisons, [sup_idx, inf_idx]))\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def _add_single_datapoint(self, new_datapoint):\n",
    "        \"\"\"Adds a single datapoint to the existing dataset and returns index.\n",
    "        \n",
    "        Args:\n",
    "            new_datapoint: The new datapoint to be added.        \n",
    "            \n",
    "        Returns:\n",
    "            x_new_idx: The index of the new datapoint in the existing dataset.\n",
    "        \"\"\"\n",
    "        self.datapoints = np.vstack((self.datapoints, new_datapoint))\n",
    "        new_datapoint_index = self.datapoints.shape[0] - 1\n",
    "        return new_datapoint_index\n",
    "\n",
    "    def get_index(self, datapoint):\n",
    "        \"\"\"Gets the index of a datapoint in the dataset.\n",
    "        \n",
    "        Args:\n",
    "            datapoint: A single datapoint.\n",
    "        \n",
    "        Returns:            \n",
    "            The index of datapoint in the dataset.\n",
    "        \"\"\"\n",
    "        return np.argmax(np.sum(datapoint != self.datapoints, axis=1) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GP_pairwise:\n",
    "    \"\"\"Gaussian process with a discrete-choice probit model (latent utility function).\n",
    "    \n",
    "    Attributes:\n",
    "        sigma: Hyperparameter for std of the normal distributed noise for the utility function.\n",
    "        theta: Hyperparameter for kernel width.\n",
    "        seed: Seed for random state.\n",
    "        datapoints: Matrix for the observed data.\n",
    "        comparisons: Matrix for comparisons of the observed data.\n",
    "        f_map: Approximate utility values of the datapoints.\n",
    "        K: Covariance matrix of datapoints.\n",
    "        K_inv: Inverse of the covariance matrix of datapoints.\n",
    "        C: The matrix C for observed data.\n",
    "        C_inv: The inverse of matrix C for observed data.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, sigma=0.01, theta=50, seed=None):\n",
    "        \"\"\"Inits GP class with all attributes.\"\"\"\n",
    "        self.sigma = sigma\n",
    "        self.theta = theta\n",
    "        self.random_state = RandomState(seed)\n",
    "        self.datapoints = None\n",
    "        self.comparisons = None\n",
    "        self.f_map = None\n",
    "        self.K = None\n",
    "        self.K_inv = None\n",
    "        self.C = None\n",
    "        self.C_inv = None\n",
    "\n",
    "    def update(self, dataset):\n",
    "        \"\"\"Update the Gaussian process using the given data.\n",
    "        \n",
    "        Args:\n",
    "            dataset: Dataset consists of datapoints and comparison matrix data \n",
    "        \"\"\"\n",
    "        self.datapoints = dataset.datapoints\n",
    "        self.comparisons = dataset.comparisons\n",
    "\n",
    "        # compute the covariance matrix and its inverse\n",
    "        self.K = self._get_K(self.datapoints)\n",
    "        self.K_inv = self._get_inv(self.K)\n",
    "\n",
    "        # compute the MAP estimate of f\n",
    "        self.f_map = self._get_f_map()\n",
    "\n",
    "        # compute C matrix given f_MAP and its inverse (psudo-inverse)\n",
    "        self.C = self._get_C()\n",
    "        self.C_inv = self._get_inv(self.C)\n",
    "\n",
    "        return True \n",
    "    \n",
    "    def sample(self, sample_points):\n",
    "        \"\"\"Get a sample from the current GP at the given points.\n",
    "        \n",
    "        Args:\n",
    "            sample_points: The points at which we want to take the sample.\n",
    "            \n",
    "        Returns: \n",
    "            The values of the GP sample at the input points.\n",
    "        \"\"\"\n",
    "        # get the mean and the variance of the predictive (multivariate gaussian) distribution at the sample points\n",
    "        mean, var = self.get_Gaussian_params(sample_points, pointwise=False)\n",
    "\n",
    "        # sample from the multivariate gaussian with the given parameters\n",
    "        f_sample = self.random_state.multivariate_normal(mean, var, 1)[0]\n",
    "\n",
    "        return f_sample\n",
    "    \n",
    "    def predict(self, sample_point):\n",
    "        \"\"\"Predicts value function for a single datapoint\"\"\"\n",
    "        mean, var = self.get_Gaussian_params(np.array([sample_point]), pointwise=False)\n",
    "        f_sample = self.random_state.multivariate_normal(mean, var, 1)[0]\n",
    "        return mean\n",
    "\n",
    "    def get_Gaussian_params(self, x_new, pointwise):\n",
    "        \"\"\"Gets the Gaussian parameters.\n",
    "        \n",
    "        Args:\n",
    "            x_new: the points for which we want the predictive parameters.\n",
    "            pointwise: whether we want pointwise variance or the entire covariance matrix.\n",
    "            \n",
    "        Returns:\n",
    "            The predictive parameters of the Gaussian distribution at the given datapoints.\n",
    "        \"\"\"\n",
    "        # if we don't have any data yet, use prior GP to make predictions\n",
    "        if self.datapoints is None or self.f_map is None:\n",
    "            pred_mean, pred_var = self._evaluate_prior(x_new)\n",
    "\n",
    "        # otherwise compute predictive mean and covariance\n",
    "        else:\n",
    "            k_T = self._get_K(x_new, self.datapoints, noise=False)\n",
    "            k = self._get_K(self.datapoints, x_new, noise=False)\n",
    "            k_plus = self._get_K(x_new, noise=False)\n",
    "            pred_mean = self._prior_mean(k_plus) + np.dot(np.dot(k_T, self.K_inv),\n",
    "                                                         (self.f_map - self._prior_mean(self.datapoints)))            \n",
    "            pred_var = k_plus - np.dot(np.dot(k_T, self._get_inv(self.K + self.C_inv)), k)\n",
    "        if pointwise:\n",
    "            pred_var = pred_var.diagonal()\n",
    "\n",
    "        return pred_mean, pred_var\n",
    "\n",
    "    \n",
    "    def _get_K(self, x1, x2=None, noise=True):\n",
    "        \"\"\"Computes covariance matrix for preference data using the kernel function.\n",
    "        \n",
    "        Args:\n",
    "            x1: The datapoints for which to compute covariance matrix.\n",
    "            x2: If None, covariance matrix will be square for the input x1,\n",
    "                If not None, covariance will be between x1 (rows) and x2 (cols)\n",
    "            noise: Whether to add noise to the diagonal of the covariance matrix.\n",
    "            \n",
    "        Returns:\n",
    "            The covariance matrix K.            \n",
    "        \"\"\"\n",
    "        if x2 is None:\n",
    "            x2 = x1\n",
    "        else: \n",
    "            noise = False\n",
    "        K = self._k(np.repeat(x1, x2.shape[0], axis=0), \n",
    "                               np.tile(x2, (x1.shape[0], 1)))\n",
    "        K = K.reshape((x1.shape[0], x2.shape[0]))\n",
    "        if noise:\n",
    "            K += self.sigma ** 2 * np.eye(K.shape[0])\n",
    "        return K\n",
    "    \n",
    "    def _k(self, x1, x2):\n",
    "        \"\"\"Exponentiated quadratic kernel function\"\"\"\n",
    "        k = 0.8**2 * np.exp(-(1. / (2. * (self.theta ** 2))) * np.linalg.norm(x1 - x2, axis=1) ** 2)\n",
    "        return k\n",
    "        \n",
    "    def _get_f_map(self):\n",
    "        \"\"\"Computes maximum a posterior (MAP) evaluation of f given the data using Newton's method\n",
    "        \n",
    "        Returns: \n",
    "            MAP of the Gassian processes values at current datapoints\n",
    "        \"\"\"\n",
    "        converged = False\n",
    "        try_no = 0\n",
    "\n",
    "        f_map = None\n",
    "\n",
    "        # Newton's method to approximate f_MAP\n",
    "        while not converged and try_no < 1:\n",
    "\n",
    "            # randomly initialise f_map\n",
    "            f_map = self.random_state.uniform(0., 1., self.datapoints.shape[0])\n",
    "\n",
    "            for m in range(100):\n",
    "                # compute Z\n",
    "                f_sup = np.array([f_map[self.comparisons[i, 0]] for i in range(self.comparisons.shape[0])])\n",
    "                f_inf = np.array([f_map[self.comparisons[i, 1]] for i in range(self.comparisons.shape[0])])\n",
    "                Z = self._get_Z(f_sup, f_inf)\n",
    "                Z_logpdf = norm.logpdf(Z)\n",
    "                Z_logcdf = norm.logcdf(Z)\n",
    "\n",
    "                # compute b\n",
    "                b = self._get_b(Z_logpdf, Z_logcdf)\n",
    "\n",
    "                # compute gradient g\n",
    "                g = self._get_g(f_map, b)\n",
    "\n",
    "                # compute hessian H\n",
    "                C = self._get_C(Z)\n",
    "                H = - self.K_inv + C\n",
    "                H_inv = self._get_inv(H)\n",
    "\n",
    "                # perform update\n",
    "                update = np.dot(H_inv, g)\n",
    "                f_map -= update\n",
    "\n",
    "                # stop criterion\n",
    "                if np.linalg.norm(update) < 0.0001:\n",
    "                    converged = True\n",
    "                    break\n",
    "                                   \n",
    "            if not converged:\n",
    "                print(\"Did not converge.\")\n",
    "                try_no += 1\n",
    "\n",
    "        return f_map\n",
    "\n",
    "    def _get_Z(self, f_sup, f_inf):\n",
    "        \"\"\"Gets the random variable Z based on given sup and inf pair.\"\"\"\n",
    "        return (f_sup - f_inf) / (np.sqrt(2) * self.sigma)\n",
    "    \n",
    "    def _get_b(self, Z_logpdf, Z_logcdf):\n",
    "        \"\"\"Gets the N-dimensional vector b\"\"\"\n",
    "        h_j = np.array([np.array(self.comparisons[:, 0] == j, dtype=int) - np.array(self.comparisons[:, 1] == j, dtype=int) \n",
    "                        for j in range(self.datapoints.shape[0])])\n",
    "        \n",
    "        b = np.sum(h_j * np.exp(Z_logpdf - Z_logcdf), axis=1) / (np.sqrt(2) * self.sigma)\n",
    "        return b\n",
    "    \n",
    "    def _get_g(self, f_map, b):\n",
    "        \"\"\"Gets the gradient g\"\"\"\n",
    "        return -np.dot(self.K_inv, (f_map - self._prior_mean(self.datapoints))) + b\n",
    "\n",
    "    def _get_C(self, Z=None):\n",
    "        \"\"\"Gets the matrix C\"\"\"\n",
    "        if Z is None:\n",
    "            # compute z\n",
    "            f_sup = np.array([self.f_map[self.comparisons[i, 0]] for i in range(self.comparisons.shape[0])])\n",
    "            f_inf = np.array([self.f_map[self.comparisons[i, 1]] for i in range(self.comparisons.shape[0])])\n",
    "            Z = (f_sup - f_inf) / (np.sqrt(2) * self.sigma)\n",
    "\n",
    "        Z_logpdf = norm.logpdf(Z)\n",
    "        Z_logcdf = norm.logcdf(Z)\n",
    "\n",
    "        # init with zeros\n",
    "        C = np.zeros((self.datapoints.shape[0], self.datapoints.shape[0]))\n",
    "\n",
    "        # build up diagonal for pairs (x, x)\n",
    "        diag_arr = np.array([self._get_C_entry(m, m, Z, Z_logpdf, Z_logcdf) for m in\n",
    "                             range(self.datapoints.shape[0])])\n",
    "        np.fill_diagonal(C, diag_arr)  # happens in-place\n",
    "\n",
    "        # go through the existing list of comparisons and update C\n",
    "        for k in range(self.comparisons.shape[0]):\n",
    "            m = self.comparisons[k, 0]  # superior\n",
    "            n = self.comparisons[k, 1]  # inferior\n",
    "            C[m, n] = self._get_C_entry(m, n, Z, Z_logpdf, Z_logcdf)\n",
    "            C[n, m] = self._get_C_entry(n, m, Z, Z_logpdf, Z_logcdf)\n",
    "\n",
    "        # add jitter terms to make matrix C positive semidefinite for stable computation\n",
    "        C += np.eye(self.datapoints.shape[0]) * 0.01\n",
    "\n",
    "        return C\n",
    "\n",
    "    def _get_C_entry(self, m, n, Z, Z_logpdf, Z_logcdf):\n",
    "        \"\"\"Gets a single entry for the Hessian matrix at indices (m,n)\"\"\"\n",
    "        h_x_m = np.array(self.comparisons[:, 0] == m, dtype=int) - np.array(self.comparisons[:, 1] == m, dtype=int)\n",
    "        h_x_n = np.array(self.comparisons[:, 0] == n, dtype=int) - np.array(self.comparisons[:, 1] == n, dtype=int)\n",
    "        p = h_x_m * h_x_n * (np.exp(2.*Z_logpdf - 2.*Z_logcdf) + Z * np.exp(Z_logpdf - Z_logcdf))\n",
    "        c = - np.sum(p) / (2 * self.sigma**2)\n",
    "        return c \n",
    "    \n",
    "    \n",
    "    def _evaluate_prior(self, input_points):\n",
    "        \"\"\"Evaluates the prior distribution given some datapoints.\n",
    "        \n",
    "        Args:\n",
    "            input_points: input datapoints at which to evaluate prior distribution.\n",
    "            \n",
    "        Returns:\n",
    "            The predictive mean and covariance at the given inputs.\n",
    "        \"\"\"\n",
    "        pred_mean = self._prior_mean(input_points)\n",
    "        num_inputs = input_points.shape[0]\n",
    "        pred_cov = self._k(np.repeat(input_points, num_inputs, axis=0),\n",
    "                           np.tile(input_points, (num_inputs, 1))).reshape((num_inputs, num_inputs))\n",
    "        return pred_mean, pred_cov\n",
    "                                             \n",
    "    def _get_inv(self, M):\n",
    "        \"\"\"Computes the inverse of the given matrix or the psudoinverse.\"\"\"\n",
    "        try:\n",
    "            M_inv = np.linalg.inv(M)\n",
    "        except:\n",
    "            M_inv = np.linalg.pinv(M)\n",
    "        return M_inv\n",
    "    \n",
    "    def _prior_mean(self, x):\n",
    "        \"\"\"Returns the prior mean of zeros\"\"\"\n",
    "        m = np.zeros(x.shape[0])\n",
    "        return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AcquisitionFunction:\n",
    "    def __init__(self, input_domain, seed):\n",
    "        \"\"\" An acquirer for a discrete set of points.\n",
    "        \n",
    "        Attributes:\n",
    "            input_domain: the datapoints on which the discrete acquirer is defined.\n",
    "            random_state: based on the random seed.\n",
    "        \"\"\"\n",
    "        self.input_domain = copy.deepcopy(input_domain)\n",
    "        self.random_state = np.random.RandomState(seed)\n",
    "        self.history = np.empty((0, self.input_domain.shape[1]))\n",
    "\n",
    "\n",
    "    def get_next_point(self, dataset, gaussian_process):\n",
    "        \"\"\"Selects a single next datapoint to query.\n",
    "        \n",
    "        Args: \n",
    "            gaussian_process\n",
    "            dataset\n",
    "        \"\"\"\n",
    "        next_point_1, next_point_2 = self.get_next_point_VAR(dataset, gaussian_process)\n",
    "        self.history = np.vstack((self.history, next_point_1, next_point_2))\n",
    "        return next_point_1, next_point_2\n",
    "    \n",
    "    def get_next_point_VAR(self, dataset, gaussian_process):\n",
    "        \"\"\"Selects the next two datapoint to query using maximum uncertainty\n",
    "        \n",
    "        Args:\n",
    "            dataset\n",
    "            gaussian_process\n",
    "            \n",
    "        Returns:\n",
    "            The optimal next pair based on maximum variance.\n",
    "        \"\"\"\n",
    "        var = np.zeros(self.input_domain.shape[0])\n",
    "        batch_size = 16\n",
    "        for curr_idx in range(0, self.input_domain.shape[0]+batch_size, batch_size):\n",
    "            var[curr_idx:curr_idx+batch_size] = self._get_variance(self.input_domain[curr_idx:curr_idx+batch_size], gaussian_process)\n",
    "        # find the two points with the highest variance, and which can be queried next\n",
    "        next_point1 = self.input_domain[np.argsort(var)[-1]]\n",
    "        next_point2 = self.input_domain[np.argsort(var)[-2]]\n",
    "        next_point_idx1, next_point_idx2 = 1, 2\n",
    "        while self._check_duplicate(dataset, next_point1, next_point2):\n",
    "            next_point1 = self.input_domain[np.argsort(-var)[next_point_idx1]]\n",
    "            next_point2 = self.input_domain[np.argsort(-var)[next_point_idx2]]\n",
    "            next_point_idx1 += 1\n",
    "            next_point_idx2 += 1\n",
    "        return next_point1, next_point2\n",
    "\n",
    "    def _get_variance(self, datapoints, gaussian_process):\n",
    "        \"\"\"Obtains the predictive pointwise variance.\"\"\"\n",
    "        pred_var = gaussian_process.get_Gaussian_params(datapoints, pointwise=True)[1]\n",
    "        return pred_var    \n",
    "    \n",
    "    def _check_duplicate(self, dataset, point1, point2):\n",
    "        \"\"\"Checks if there are duplicate pairs being sampled.\"\"\"\n",
    "        if point1 not in dataset.datapoints or point2 not in dataset.datapoints:\n",
    "            return False \n",
    "        idx1, idx2 = np.where(dataset.datapoints==point1), np.where(dataset.datapoints==point2)\n",
    "        return True if [idx1, idx2] or [idx2, idx1] in dataset.comparisons else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ComparisonOracle:\n",
    "    def __init__(self, utility_function):\n",
    "        self.utility_function = utility_function\n",
    "        \n",
    "    def compare(self, choice1, choice2):\n",
    "        if self.utility_function(choice1) > self.utility_function(choice2):\n",
    "            return choice1, choice2\n",
    "        else:\n",
    "            return choice2, choice1  \n",
    "\n",
    "def sqare_root_utility(subset):\n",
    "    return sum([x ** 0.5 for x in subset])\n",
    "\n",
    "def cube_root_utility(subset):\n",
    "    return sum([x ** (1./3) for x in subset])\n",
    "\n",
    "def log_utility(subset):\n",
    "    return sum([np.log(x) for x in subset])\n",
    "\n",
    "def train(gp, af, max_q=50):\n",
    "    for i in range(1, max_q+1): \n",
    "        print('-------------Train', i, '--------------')\n",
    "        next1, next2 = af.get_next_point(dataset, gp)\n",
    "        print('Optimal next pair is:', next1, next2)\n",
    "        sup, inf = oracle.compare(next1, next2)\n",
    "        dataset.add_single_comparison(sup, inf)\n",
    "        print('User chooses:', sup)\n",
    "        print('Updating GP with new data...')\n",
    "        gp.update(dataset)\n",
    "    print('---------Finished training!----------\\n') \n",
    "    \n",
    "def test(gp, af, test_size=50):\n",
    "    gp_oracle = ComparisonOracle(gp.predict)\n",
    "    success = 0\n",
    "    for i in range(1, test_size+1):\n",
    "        print('---------------Test', i, '---------------')\n",
    "        test1 = np.random.randint(1, 50, 2)\n",
    "        test2 = np.random.randint(1, 50, 2)\n",
    "        gp_op = gp_oracle.compare(test1, test2)[0]\n",
    "        oracle_op = oracle.compare(test1, test2)[0]\n",
    "        print('Testing pair:', test1, test2)\n",
    "        print('GP chooses', gp_op)\n",
    "        print('User chooses', oracle_op)\n",
    "        if np.array_equal(gp_op, oracle_op):\n",
    "            success += 1\n",
    "    print('-----------Finished testing!----------\\n') \n",
    "    print(\"Accuracy: \", success/test_size)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Train 1 --------------\n",
      "Optimal next pair is: [99  1] [25 75]\n",
      "User chooses: [25 75]\n",
      "Updating GP with new data...\n",
      "-------------Train 2 --------------\n",
      "Optimal next pair is: [62 38] [61 39]\n",
      "User chooses: [61 39]\n",
      "Updating GP with new data...\n",
      "-------------Train 3 --------------\n",
      "Optimal next pair is: [62 38] [60 40]\n",
      "User chooses: [60 40]\n",
      "Updating GP with new data...\n",
      "-------------Train 4 --------------\n",
      "Optimal next pair is: [60 40] [63 37]\n",
      "User chooses: [60 40]\n",
      "Updating GP with new data...\n",
      "-------------Train 5 --------------\n",
      "Optimal next pair is: [63 37] [59 41]\n",
      "User chooses: [59 41]\n",
      "Updating GP with new data...\n",
      "-------------Train 6 --------------\n",
      "Optimal next pair is: [59 41] [64 36]\n",
      "User chooses: [59 41]\n",
      "Updating GP with new data...\n",
      "-------------Train 7 --------------\n",
      "Optimal next pair is: [64 36] [ 1 99]\n",
      "User chooses: [64 36]\n",
      "Updating GP with new data...\n",
      "-------------Train 8 --------------\n",
      "Optimal next pair is: [86 14] [85 15]\n",
      "User chooses: [85 15]\n",
      "Updating GP with new data...\n",
      "-------------Train 9 --------------\n",
      "Optimal next pair is: [12 88] [11 89]\n",
      "User chooses: [12 88]\n",
      "Updating GP with new data...\n",
      "-------------Train 10 --------------\n",
      "Optimal next pair is: [12 88] [10 90]\n",
      "User chooses: [12 88]\n",
      "Updating GP with new data...\n",
      "-------------Train 11 --------------\n",
      "Optimal next pair is: [10 90] [13 87]\n",
      "User chooses: [13 87]\n",
      "Updating GP with new data...\n",
      "-------------Train 12 --------------\n",
      "Optimal next pair is: [13 87] [ 9 91]\n",
      "User chooses: [13 87]\n",
      "Updating GP with new data...\n",
      "-------------Train 13 --------------\n",
      "Optimal next pair is: [ 9 91] [14 86]\n",
      "User chooses: [14 86]\n",
      "Updating GP with new data...\n",
      "-------------Train 14 --------------\n",
      "Optimal next pair is: [14 86] [ 8 92]\n",
      "User chooses: [14 86]\n",
      "Updating GP with new data...\n",
      "-------------Train 15 --------------\n",
      "Optimal next pair is: [ 8 92] [15 85]\n",
      "User chooses: [15 85]\n",
      "Updating GP with new data...\n",
      "-------------Train 16 --------------\n",
      "Optimal next pair is: [15 85] [ 7 93]\n",
      "User chooses: [15 85]\n",
      "Updating GP with new data...\n",
      "-------------Train 17 --------------\n",
      "Optimal next pair is: [ 7 93] [16 84]\n",
      "User chooses: [16 84]\n",
      "Updating GP with new data...\n",
      "-------------Train 18 --------------\n",
      "Optimal next pair is: [16 84] [ 6 94]\n",
      "User chooses: [16 84]\n",
      "Updating GP with new data...\n",
      "-------------Train 19 --------------\n",
      "Optimal next pair is: [ 6 94] [17 83]\n",
      "User chooses: [17 83]\n",
      "Updating GP with new data...\n",
      "-------------Train 20 --------------\n",
      "Optimal next pair is: [85 15] [84 16]\n",
      "User chooses: [84 16]\n",
      "Updating GP with new data...\n",
      "---------Finished training!----------\n",
      "\n",
      "---------------Test 1 ---------------\n",
      "Testing pair: [ 6 14] [ 6 18]\n",
      "GP chooses [ 6 18]\n",
      "User chooses [ 6 18]\n",
      "---------------Test 2 ---------------\n",
      "Testing pair: [16 29] [39 47]\n",
      "GP chooses [39 47]\n",
      "User chooses [39 47]\n",
      "---------------Test 3 ---------------\n",
      "Testing pair: [ 5 25] [39 13]\n",
      "GP chooses [39 13]\n",
      "User chooses [39 13]\n",
      "---------------Test 4 ---------------\n",
      "Testing pair: [17 49] [30 43]\n",
      "GP chooses [30 43]\n",
      "User chooses [30 43]\n",
      "---------------Test 5 ---------------\n",
      "Testing pair: [13 26] [46  6]\n",
      "GP chooses [13 26]\n",
      "User chooses [46  6]\n",
      "---------------Test 6 ---------------\n",
      "Testing pair: [41 36] [18  7]\n",
      "GP chooses [41 36]\n",
      "User chooses [41 36]\n",
      "---------------Test 7 ---------------\n",
      "Testing pair: [25 23] [31  3]\n",
      "GP chooses [25 23]\n",
      "User chooses [25 23]\n",
      "---------------Test 8 ---------------\n",
      "Testing pair: [26 22] [26 15]\n",
      "GP chooses [26 22]\n",
      "User chooses [26 22]\n",
      "---------------Test 9 ---------------\n",
      "Testing pair: [20 13] [30 26]\n",
      "GP chooses [30 26]\n",
      "User chooses [30 26]\n",
      "---------------Test 10 ---------------\n",
      "Testing pair: [47 26] [19 12]\n",
      "GP chooses [47 26]\n",
      "User chooses [47 26]\n",
      "---------------Test 11 ---------------\n",
      "Testing pair: [48 38] [10 43]\n",
      "GP chooses [48 38]\n",
      "User chooses [48 38]\n",
      "---------------Test 12 ---------------\n",
      "Testing pair: [19 34] [ 4 15]\n",
      "GP chooses [19 34]\n",
      "User chooses [19 34]\n",
      "---------------Test 13 ---------------\n",
      "Testing pair: [44  4] [37 41]\n",
      "GP chooses [37 41]\n",
      "User chooses [37 41]\n",
      "---------------Test 14 ---------------\n",
      "Testing pair: [21 14] [11  7]\n",
      "GP chooses [21 14]\n",
      "User chooses [21 14]\n",
      "---------------Test 15 ---------------\n",
      "Testing pair: [31 13] [29 42]\n",
      "GP chooses [29 42]\n",
      "User chooses [29 42]\n",
      "---------------Test 16 ---------------\n",
      "Testing pair: [28  3] [ 5 25]\n",
      "GP chooses [ 5 25]\n",
      "User chooses [ 5 25]\n",
      "---------------Test 17 ---------------\n",
      "Testing pair: [19 32] [18 48]\n",
      "GP chooses [18 48]\n",
      "User chooses [18 48]\n",
      "---------------Test 18 ---------------\n",
      "Testing pair: [20 26] [36 35]\n",
      "GP chooses [36 35]\n",
      "User chooses [36 35]\n",
      "---------------Test 19 ---------------\n",
      "Testing pair: [34 45] [18  7]\n",
      "GP chooses [34 45]\n",
      "User chooses [34 45]\n",
      "---------------Test 20 ---------------\n",
      "Testing pair: [ 4 35] [ 9 33]\n",
      "GP chooses [ 9 33]\n",
      "User chooses [ 9 33]\n",
      "---------------Test 21 ---------------\n",
      "Testing pair: [23 17] [28 48]\n",
      "GP chooses [28 48]\n",
      "User chooses [28 48]\n",
      "---------------Test 22 ---------------\n",
      "Testing pair: [29 22] [48 48]\n",
      "GP chooses [48 48]\n",
      "User chooses [48 48]\n",
      "---------------Test 23 ---------------\n",
      "Testing pair: [42 31] [9 4]\n",
      "GP chooses [42 31]\n",
      "User chooses [42 31]\n",
      "---------------Test 24 ---------------\n",
      "Testing pair: [33 35] [20 21]\n",
      "GP chooses [33 35]\n",
      "User chooses [33 35]\n",
      "---------------Test 25 ---------------\n",
      "Testing pair: [35 47] [45 32]\n",
      "GP chooses [35 47]\n",
      "User chooses [35 47]\n",
      "---------------Test 26 ---------------\n",
      "Testing pair: [34 19] [48 16]\n",
      "GP chooses [34 19]\n",
      "User chooses [48 16]\n",
      "---------------Test 27 ---------------\n",
      "Testing pair: [33  1] [32 18]\n",
      "GP chooses [32 18]\n",
      "User chooses [32 18]\n",
      "---------------Test 28 ---------------\n",
      "Testing pair: [19 42] [27 46]\n",
      "GP chooses [27 46]\n",
      "User chooses [27 46]\n",
      "---------------Test 29 ---------------\n",
      "Testing pair: [30 32] [10 39]\n",
      "GP chooses [30 32]\n",
      "User chooses [30 32]\n",
      "---------------Test 30 ---------------\n",
      "Testing pair: [22 30] [24 25]\n",
      "GP chooses [22 30]\n",
      "User chooses [22 30]\n",
      "-----------Finished testing!----------\n",
      "\n",
      "Accuracy:  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "#### Simulation for pairwise-comparison experiment \n",
    "## Setup: \n",
    "##      - want to hire <= 100 people\n",
    "##      - each subset is represented by [W, M] -> [number of women, number of men]\n",
    "##      - capacity constraint: W + M <= 100\n",
    "##      - value function defined on the subsets \n",
    "##      - true value function: square-root / cubic-root / log utility\n",
    "## Goal:\n",
    "##      - learn value function using GP + active learning (choosing optimal pair sequentially)\n",
    "##      - Use as few query as possible (using 20 queries in the current example)\n",
    "\n",
    "#### set seed for experiment\n",
    "\n",
    "#### Create oracle w/ sqaure root utility, cubic or log utility\n",
    "oracle = ComparisonOracle(cube_root_utility)\n",
    "\n",
    "#### Create dataset object\n",
    "dataset = Dataset(2)\n",
    "\n",
    "#### Create query domain\n",
    "input_domain = np.array([[x, 100 - x] for x in range(1, 100)])\n",
    "\n",
    "#### GP + AF\n",
    "gp = GP_pairwise(theta=20, seed=1) # build a new GP process\n",
    "af = AcquisitionFunction(input_domain, seed=10) # build a new acquisition function\n",
    "\n",
    "#### Training with active learning on 20 queries \n",
    "train(gp, af, 20)\n",
    "\n",
    "#### Out-of-sample testing on 30 queries \n",
    "test(gp, af, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Visualization for utility functions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
